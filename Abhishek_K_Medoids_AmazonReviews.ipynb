{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# K-Medoids Clustering on Amazon Food Reviews"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# OBJECTIVE: To perform K-Medoids clustering on Amazon Food reviews data and observe the different clusters obtained"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "#=====================Importing the required libraries=========================#\n",
    "\n",
    "import sqlite3\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import nltk\n",
    "import string\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer\n",
    "import re\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import roc_curve, auc\n",
    "from nltk.stem.porter import PorterStemmer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the required sqlite version of the Amazon Food Reviews dataset\n",
    "\n",
    "# Establishing a connection with the database\n",
    "con = sqlite3.connect('database.sqlite')\n",
    "\n",
    "# Storing the data in a dataframe acquired from the connection\n",
    "\n",
    "reviews_data = pd.read_sql_query(\"\"\"SELECT * FROM Reviews\"\"\", con)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>B001E4KFG0</td>\n",
       "      <td>A3SGXH7AUHU8GW</td>\n",
       "      <td>delmartian</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1303862400</td>\n",
       "      <td>Good Quality Dog Food</td>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>B00813GRG4</td>\n",
       "      <td>A1D87F6ZCVE5NK</td>\n",
       "      <td>dll pa</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1346976000</td>\n",
       "      <td>Not as Advertised</td>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>3</td>\n",
       "      <td>B000LQOCH0</td>\n",
       "      <td>ABXLMWJIXXAIN</td>\n",
       "      <td>Natalia Corres \"Natalia Corres\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1219017600</td>\n",
       "      <td>\"Delight\" says it all</td>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>4</td>\n",
       "      <td>B000UA0QIQ</td>\n",
       "      <td>A395BORC6FGVXV</td>\n",
       "      <td>Karl</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>1307923200</td>\n",
       "      <td>Cough Medicine</td>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>5</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1UQRSCLF8GW1T</td>\n",
       "      <td>Michael D. Bigham \"M. Wassir\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1350777600</td>\n",
       "      <td>Great taffy</td>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>6</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>ADT0SRK1MGOEU</td>\n",
       "      <td>Twoapennything</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>1342051200</td>\n",
       "      <td>Nice Taffy</td>\n",
       "      <td>I got a wild hair for taffy and ordered this f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>7</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A1SP2KVKFXXRU1</td>\n",
       "      <td>David C. Sullivan</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1340150400</td>\n",
       "      <td>Great!  Just as good as the expensive brands!</td>\n",
       "      <td>This saltwater taffy had great flavors and was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>8</td>\n",
       "      <td>B006K2ZZ7K</td>\n",
       "      <td>A3JRGQVEQN31IQ</td>\n",
       "      <td>Pamela G. Williams</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1336003200</td>\n",
       "      <td>Wonderful, tasty taffy</td>\n",
       "      <td>This taffy is so good.  It is very soft and ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>9</td>\n",
       "      <td>B000E7L2R4</td>\n",
       "      <td>A1MZYO9TZK0BBI</td>\n",
       "      <td>R. James</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1322006400</td>\n",
       "      <td>Yay Barley</td>\n",
       "      <td>Right now I'm mostly just sprouting this so my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>10</td>\n",
       "      <td>B00171APVA</td>\n",
       "      <td>A21BT40VZCCYT4</td>\n",
       "      <td>Carol A. Reed</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1351209600</td>\n",
       "      <td>Healthy Dog Food</td>\n",
       "      <td>This is a very healthy dog food. Good for thei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Id   ProductId          UserId                      ProfileName  \\\n",
       "0   1  B001E4KFG0  A3SGXH7AUHU8GW                       delmartian   \n",
       "1   2  B00813GRG4  A1D87F6ZCVE5NK                           dll pa   \n",
       "2   3  B000LQOCH0   ABXLMWJIXXAIN  Natalia Corres \"Natalia Corres\"   \n",
       "3   4  B000UA0QIQ  A395BORC6FGVXV                             Karl   \n",
       "4   5  B006K2ZZ7K  A1UQRSCLF8GW1T    Michael D. Bigham \"M. Wassir\"   \n",
       "5   6  B006K2ZZ7K   ADT0SRK1MGOEU                   Twoapennything   \n",
       "6   7  B006K2ZZ7K  A1SP2KVKFXXRU1                David C. Sullivan   \n",
       "7   8  B006K2ZZ7K  A3JRGQVEQN31IQ               Pamela G. Williams   \n",
       "8   9  B000E7L2R4  A1MZYO9TZK0BBI                         R. James   \n",
       "9  10  B00171APVA  A21BT40VZCCYT4                    Carol A. Reed   \n",
       "\n",
       "   HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "0                     1                       1      5  1303862400   \n",
       "1                     0                       0      1  1346976000   \n",
       "2                     1                       1      4  1219017600   \n",
       "3                     3                       3      2  1307923200   \n",
       "4                     0                       0      5  1350777600   \n",
       "5                     0                       0      4  1342051200   \n",
       "6                     0                       0      5  1340150400   \n",
       "7                     0                       0      5  1336003200   \n",
       "8                     1                       1      5  1322006400   \n",
       "9                     0                       0      5  1351209600   \n",
       "\n",
       "                                         Summary  \\\n",
       "0                          Good Quality Dog Food   \n",
       "1                              Not as Advertised   \n",
       "2                          \"Delight\" says it all   \n",
       "3                                 Cough Medicine   \n",
       "4                                    Great taffy   \n",
       "5                                     Nice Taffy   \n",
       "6  Great!  Just as good as the expensive brands!   \n",
       "7                         Wonderful, tasty taffy   \n",
       "8                                     Yay Barley   \n",
       "9                               Healthy Dog Food   \n",
       "\n",
       "                                                Text  \n",
       "0  I have bought several of the Vitality canned d...  \n",
       "1  Product arrived labeled as Jumbo Salted Peanut...  \n",
       "2  This is a confection that has been around a fe...  \n",
       "3  If you are looking for the secret ingredient i...  \n",
       "4  Great taffy at a great price.  There was a wid...  \n",
       "5  I got a wild hair for taffy and ordered this f...  \n",
       "6  This saltwater taffy had great flavors and was...  \n",
       "7  This taffy is so good.  It is very soft and ch...  \n",
       "8  Right now I'm mostly just sprouting this so my...  \n",
       "9  This is a very healthy dog food. Good for thei...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the first few rows of the data to ensure we have the right data\n",
    "\n",
    "reviews_data.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Id</th>\n",
       "      <th>ProductId</th>\n",
       "      <th>UserId</th>\n",
       "      <th>ProfileName</th>\n",
       "      <th>HelpfulnessNumerator</th>\n",
       "      <th>HelpfulnessDenominator</th>\n",
       "      <th>Score</th>\n",
       "      <th>Time</th>\n",
       "      <th>Summary</th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>568444</th>\n",
       "      <td>568445</td>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A2SD7TY3IOX69B</td>\n",
       "      <td>BayBay \"BayBay Knows Best\"</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1245369600</td>\n",
       "      <td>Best Value for Chinese 5 Spice</td>\n",
       "      <td>As a foodie, I use a lot of Chinese 5 Spice po...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568445</th>\n",
       "      <td>568446</td>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A2E5C8TTAED4CQ</td>\n",
       "      <td>S. Linkletter</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1268006400</td>\n",
       "      <td>Five Spice Powder</td>\n",
       "      <td>You can make this mix yourself, but the Star A...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568446</th>\n",
       "      <td>568447</td>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A2P9W8T7NTLG2Z</td>\n",
       "      <td>Andy</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1328918400</td>\n",
       "      <td>Mixed wrong</td>\n",
       "      <td>I had ordered some of these a few months back ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568447</th>\n",
       "      <td>568448</td>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>APWCOAVILK94B</td>\n",
       "      <td>Real Named Person \"wowzee\"</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1322524800</td>\n",
       "      <td>If its all natural, this is like panacea of Sp...</td>\n",
       "      <td>Hoping there is no MSG in this, this tastes ex...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568448</th>\n",
       "      <td>568449</td>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A1F6BHEYB7R6R7</td>\n",
       "      <td>James Braley</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1308096000</td>\n",
       "      <td>Very large ground spice jars.</td>\n",
       "      <td>My only complaint is that there's so much of i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568449</th>\n",
       "      <td>568450</td>\n",
       "      <td>B001EO7N10</td>\n",
       "      <td>A28KG5XORO54AY</td>\n",
       "      <td>Lettie D. Carter</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1299628800</td>\n",
       "      <td>Will not do without</td>\n",
       "      <td>Great for sesame chicken..this is a good if no...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568450</th>\n",
       "      <td>568451</td>\n",
       "      <td>B003S1WTCU</td>\n",
       "      <td>A3I8AFVPEE8KI5</td>\n",
       "      <td>R. Sawyer</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1331251200</td>\n",
       "      <td>disappointed</td>\n",
       "      <td>I'm disappointed with the flavor. The chocolat...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568451</th>\n",
       "      <td>568452</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A121AA1GQV751Z</td>\n",
       "      <td>pksd \"pk_007\"</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1329782400</td>\n",
       "      <td>Perfect for our maltipoo</td>\n",
       "      <td>These stars are small, so you can give 10-15 o...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568452</th>\n",
       "      <td>568453</td>\n",
       "      <td>B004I613EE</td>\n",
       "      <td>A3IBEVCTXKNOH</td>\n",
       "      <td>Kathy A. Welch \"katwel\"</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1331596800</td>\n",
       "      <td>Favorite Training and reward treat</td>\n",
       "      <td>These are the BEST treats for training and rew...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>568453</th>\n",
       "      <td>568454</td>\n",
       "      <td>B001LR2CU2</td>\n",
       "      <td>A3LGQPJCZVL9UC</td>\n",
       "      <td>srfell17</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>1338422400</td>\n",
       "      <td>Great Honey</td>\n",
       "      <td>I am very satisfied ,product is as advertised,...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "            Id   ProductId          UserId                 ProfileName  \\\n",
       "568444  568445  B001EO7N10  A2SD7TY3IOX69B  BayBay \"BayBay Knows Best\"   \n",
       "568445  568446  B001EO7N10  A2E5C8TTAED4CQ               S. Linkletter   \n",
       "568446  568447  B001EO7N10  A2P9W8T7NTLG2Z                        Andy   \n",
       "568447  568448  B001EO7N10   APWCOAVILK94B  Real Named Person \"wowzee\"   \n",
       "568448  568449  B001EO7N10  A1F6BHEYB7R6R7                James Braley   \n",
       "568449  568450  B001EO7N10  A28KG5XORO54AY            Lettie D. Carter   \n",
       "568450  568451  B003S1WTCU  A3I8AFVPEE8KI5                   R. Sawyer   \n",
       "568451  568452  B004I613EE  A121AA1GQV751Z               pksd \"pk_007\"   \n",
       "568452  568453  B004I613EE   A3IBEVCTXKNOH     Kathy A. Welch \"katwel\"   \n",
       "568453  568454  B001LR2CU2  A3LGQPJCZVL9UC                    srfell17   \n",
       "\n",
       "        HelpfulnessNumerator  HelpfulnessDenominator  Score        Time  \\\n",
       "568444                     3                       3      5  1245369600   \n",
       "568445                     2                       2      5  1268006400   \n",
       "568446                     0                       0      2  1328918400   \n",
       "568447                     0                       0      5  1322524800   \n",
       "568448                     0                       0      5  1308096000   \n",
       "568449                     0                       0      5  1299628800   \n",
       "568450                     0                       0      2  1331251200   \n",
       "568451                     2                       2      5  1329782400   \n",
       "568452                     1                       1      5  1331596800   \n",
       "568453                     0                       0      5  1338422400   \n",
       "\n",
       "                                                  Summary  \\\n",
       "568444                     Best Value for Chinese 5 Spice   \n",
       "568445                                  Five Spice Powder   \n",
       "568446                                        Mixed wrong   \n",
       "568447  If its all natural, this is like panacea of Sp...   \n",
       "568448                      Very large ground spice jars.   \n",
       "568449                                Will not do without   \n",
       "568450                                       disappointed   \n",
       "568451                           Perfect for our maltipoo   \n",
       "568452                 Favorite Training and reward treat   \n",
       "568453                                        Great Honey   \n",
       "\n",
       "                                                     Text  \n",
       "568444  As a foodie, I use a lot of Chinese 5 Spice po...  \n",
       "568445  You can make this mix yourself, but the Star A...  \n",
       "568446  I had ordered some of these a few months back ...  \n",
       "568447  Hoping there is no MSG in this, this tastes ex...  \n",
       "568448  My only complaint is that there's so much of i...  \n",
       "568449  Great for sesame chicken..this is a good if no...  \n",
       "568450  I'm disappointed with the flavor. The chocolat...  \n",
       "568451  These stars are small, so you can give 10-15 o...  \n",
       "568452  These are the BEST treats for training and rew...  \n",
       "568453  I am very satisfied ,product is as advertised,...  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the last few rows of the data to ensure we have the right data\n",
    "\n",
    "reviews_data.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = reviews_data[['Score']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "For further processing and obtaining the number of clusters required we shall require only the text data, therefore we \n",
    "will extract only the text variable from the dataset.\n",
    "'''\n",
    "\n",
    "text_data = reviews_data[['Text']]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I have bought several of the Vitality canned d...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Product arrived labeled as Jumbo Salted Peanut...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is a confection that has been around a fe...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>If you are looking for the secret ingredient i...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Great taffy at a great price.  There was a wid...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>I got a wild hair for taffy and ordered this f...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>This saltwater taffy had great flavors and was...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This taffy is so good.  It is very soft and ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Right now I'm mostly just sprouting this so my...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>This is a very healthy dog food. Good for thei...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  I have bought several of the Vitality canned d...\n",
       "1  Product arrived labeled as Jumbo Salted Peanut...\n",
       "2  This is a confection that has been around a fe...\n",
       "3  If you are looking for the secret ingredient i...\n",
       "4  Great taffy at a great price.  There was a wid...\n",
       "5  I got a wild hair for taffy and ordered this f...\n",
       "6  This saltwater taffy had great flavors and was...\n",
       "7  This taffy is so good.  It is very soft and ch...\n",
       "8  Right now I'm mostly just sprouting this so my...\n",
       "9  This is a very healthy dog food. Good for thei..."
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Taking a look at the first few rows of the data to ensure that we have the right data\n",
    "\n",
    "text_data.head(10)\n",
    "\n",
    "# We can say that we have the right data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(568454, 1)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us look at the shape of the data\n",
    "\n",
    "text_data.shape\n",
    "\n",
    "# The data has 568454 rows and 1 column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the vaues of text_data in X1 to avoid unhashable slice error\n",
    "\n",
    "X1 = text_data.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# As the time complexity for hierarchical clustering is large, we will extract only 4000 reviews and perform clustering\n",
    "\n",
    "import random\n",
    "\n",
    "n = 568454\n",
    "m = 4000\n",
    "p = m/n\n",
    "\n",
    "sample_reviews = [];\n",
    "\n",
    "for i in range(0,n):\n",
    "    if random.random() <= p:\n",
    "        sample_reviews.append(X1[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_reviews = pd.DataFrame(sample_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the name to the columns\n",
    "\n",
    "text_reviews.columns = ['Reviews']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This product serves me well as a source of ele...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This cat food was recommended by my vet becaus...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you're looking for an energy boost without ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"These are delicious! The chocolate is excelle...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After looking at the pictures someone put on h...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews\n",
       "0  This product serves me well as a source of ele...\n",
       "1  This cat food was recommended by my vet becaus...\n",
       "2  If you're looking for an energy boost without ...\n",
       "3  \"These are delicious! The chocolate is excelle...\n",
       "4  After looking at the pictures someone put on h..."
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the first few rows of the dataframe\n",
    "\n",
    "text_reviews.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n",
      "This product serves me well as a source of electrolytes during and after a long run or bike ride.<br />I have tried all of the flavors but really do like the grapefruit flavor... no after-taste and I actually like the slight carbonation.<br />I use other Hammer products and really like their whole product line.\n"
     ]
    }
   ],
   "source": [
    "# Now we will perform the data cleaning and transformation \n",
    "\n",
    "# We can see that there are unknown elements like html tags in the data. We need to remove those\n",
    "\n",
    "# find sentences containing HTML tags\n",
    "\n",
    "import re\n",
    "\n",
    "i=0;\n",
    "for sent in text_reviews['Reviews'].values:\n",
    "    if (len(re.findall('<.*?>', sent))):\n",
    "        print(i)\n",
    "        print(sent)\n",
    "        break;\n",
    "    i += 1; \n",
    "    \n",
    "# We can see that there is data consisting of html tags, we need to remove these tags"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\kulkarni\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "'''\n",
    "We will perform the data cleaning steps on the text data.For that we will perform word stemmatization and \n",
    "cleaning html and punctuation marks.\n",
    "'''\n",
    "\n",
    "#import re\n",
    "'''import string\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.stem import PorterStemmer\n",
    "from nltk.stem.wordnet import WordNetLemmatizer'''\n",
    "\n",
    "nltk.download('stopwords')\n",
    "\n",
    "stop = set(stopwords.words('english')) #set of stopwords\n",
    "sno = nltk.stem.SnowballStemmer('english') #initialising the snowball stemmer\n",
    "\n",
    "def cleanhtml(sentence): #function to clean the word of any html-tags\n",
    "    cleanr = re.compile('<.*?>')\n",
    "    cleantext = re.sub(cleanr, ' ', sentence)\n",
    "    return cleantext\n",
    "def cleanpunc(sentence): #function to clean the word of any punctuation or special characters\n",
    "    cleaned = re.sub(r'[?|!|\\'|\"|#]',r'',sentence)\n",
    "    cleaned = re.sub(r'[.|,|)|(|\\|/]',r' ',cleaned)\n",
    "    return  cleaned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Applying the stopwords removal, html removal, punctuation marks removal on the text_data dataframe\n",
    "\n",
    "#Code for implementing step-by-step the checks mentioned in the pre-processing phase\n",
    "# this code takes a while to run as it needs to run on 500k sentences.\n",
    "i=0\n",
    "str1=' '\n",
    "final_string=[]\n",
    "#all_positive_words=[] # store words from +ve reviews here\n",
    "#all_negative_words=[] # store words from -ve reviews here.\n",
    "s=''\n",
    "for sent in text_reviews['Reviews'].values:\n",
    "    filtered_sentence=[]\n",
    "    #print(sent);\n",
    "    sent=cleanhtml(sent) # remove HTMl tags\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if((cleaned_words.isalpha()) & (len(cleaned_words)>2)):    \n",
    "                if(cleaned_words.lower() not in stop):\n",
    "                    s=(sno.stem(cleaned_words.lower())).encode('utf8')\n",
    "                    filtered_sentence.append(s)\n",
    "                    #if (final['Score'].values)[i] == 'positive': \n",
    "                    #    all_positive_words.append(s) #list of all words used to describe positive reviews\n",
    "                    #if(final['Score'].values)[i] == 'negative':\n",
    "                    #    all_negative_words.append(s) #list of all words used to describe negative reviews reviews\n",
    "                else:\n",
    "                    continue\n",
    "            else:\n",
    "                continue \n",
    "    #print(filtered_sentence)\n",
    "    str1 = b\" \".join(filtered_sentence) #final string of cleaned words\n",
    "    #print(\"***********************************************************************\")\n",
    "    \n",
    "    final_string.append(str1)\n",
    "    i+=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assigning the 'final_string' array to the 'text_data' dataframe\n",
    "\n",
    "text_reviews['Cleaned_Text'] = final_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This product serves me well as a source of ele...</td>\n",
       "      <td>b'product serv well sourc electrolyt long run ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This cat food was recommended by my vet becaus...</td>\n",
       "      <td>b'cat food recommend vet year old cleo cat tro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you're looking for an energy boost without ...</td>\n",
       "      <td>b'your look energi boost without artifici swee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"These are delicious! The chocolate is excelle...</td>\n",
       "      <td>b'delici chocol excel espresso bean perfect ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After looking at the pictures someone put on h...</td>\n",
       "      <td>b'look pictur someon put show crush box write ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews  \\\n",
       "0  This product serves me well as a source of ele...   \n",
       "1  This cat food was recommended by my vet becaus...   \n",
       "2  If you're looking for an energy boost without ...   \n",
       "3  \"These are delicious! The chocolate is excelle...   \n",
       "4  After looking at the pictures someone put on h...   \n",
       "\n",
       "                                        Cleaned_Text  \n",
       "0  b'product serv well sourc electrolyt long run ...  \n",
       "1  b'cat food recommend vet year old cleo cat tro...  \n",
       "2  b'your look energi boost without artifici swee...  \n",
       "3  b'delici chocol excel espresso bean perfect ro...  \n",
       "4  b'look pictur someon put show crush box write ...  "
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking whether the cleaned text has been assigned to the text_data dataframe\n",
    "\n",
    "text_reviews.head()\n",
    "\n",
    "# We can see that the data has been assigned to the dataframe"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3982</th>\n",
       "      <td>Laura Scudder's Organic Smooth Peanut Butter, ...</td>\n",
       "      <td>b'laura scudder organ smooth peanut butter buy...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>My cats haven't been this excited to eat since...</td>\n",
       "      <td>b'cat havent excit eat sinc time fed day fresh...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>I'd never heard of this brand but they were ve...</td>\n",
       "      <td>b'never heard brand cheap amazon extrem surpri...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3985</th>\n",
       "      <td>Everyone has their own preferences, I know -- ...</td>\n",
       "      <td>b'everyon prefer know actual like flavor wife ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>The salt liocorice was very good.  It came nic...</td>\n",
       "      <td>b'salt liocoric good came nice moist even thre...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Reviews  \\\n",
       "3982  Laura Scudder's Organic Smooth Peanut Butter, ...   \n",
       "3983  My cats haven't been this excited to eat since...   \n",
       "3984  I'd never heard of this brand but they were ve...   \n",
       "3985  Everyone has their own preferences, I know -- ...   \n",
       "3986  The salt liocorice was very good.  It came nic...   \n",
       "\n",
       "                                           Cleaned_Text  \n",
       "3982  b'laura scudder organ smooth peanut butter buy...  \n",
       "3983  b'cat havent excit eat sinc time fed day fresh...  \n",
       "3984  b'never heard brand cheap amazon extrem surpri...  \n",
       "3985  b'everyon prefer know actual like flavor wife ...  \n",
       "3986  b'salt liocoric good came nice moist even thre...  "
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the last few rows of the dataframe\n",
    "\n",
    "text_reviews.tail()\n",
    "\n",
    "# We can say that we have the right data after cleaning the text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3987, 2)"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us once check the dimensions of the dataframe just to be sure\n",
    "\n",
    "text_reviews.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will only take the cleaned version of the text and make a new dataframe\n",
    "\n",
    "final_text = text_reviews[['Cleaned_Text']].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Cleaned_Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>b'product serv well sourc electrolyt long run ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>b'cat food recommend vet year old cleo cat tro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>b'your look energi boost without artifici swee...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>b'delici chocol excel espresso bean perfect ro...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>b'look pictur someon put show crush box write ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                        Cleaned_Text\n",
       "0  b'product serv well sourc electrolyt long run ...\n",
       "1  b'cat food recommend vet year old cleo cat tro...\n",
       "2  b'your look energi boost without artifici swee...\n",
       "3  b'delici chocol excel espresso bean perfect ro...\n",
       "4  b'look pictur someon put show crush box write ..."
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the first few rows of the data\n",
    "\n",
    "final_text.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(3987, 1)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "final_text.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating different models of text representation and applying hierarchical clustering"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a BoW representation of the reviews data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "#BoW\n",
    "count_vect = CountVectorizer() #in scikit-learn\n",
    "final_counts = count_vect.fit_transform(final_text['Cleaned_Text'].values).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# final_counts is in the form of matrix, we will convert it to an array\n",
    "\n",
    "#A = np.squeeze(np.asarray(M))\n",
    "\n",
    "final_counts_array = np.squeeze(np.asarray(final_counts))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Checking the type of final_counts_array to be sure\n",
    "\n",
    "print(type(final_counts_array))\n",
    "\n",
    "# We can see that it is a n-dimensional numpy array."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyclust"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pyclust import KMedoids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "clusters =KMedoids(n_clusters=2)\n",
    "clusters.fit(D)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying K-Medoids Clustering to BoW representation of reviews data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "# Although the data has been divided into 5 clusters, for our covenience we have divided the data into positive and negative classes. We will use k-medoids to divide the data into 2 clusters and observe whether right clusters have been created."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considering 2 as the number of clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "# import pyclust library for K-Medoids clustering\n",
    "import pyclust\n",
    "from pyclust import KMedoids\n",
    "\n",
    "# Creating 2 as the number of clusters \n",
    "clustersbow_2 = KMedoids(n_clusters=2)\n",
    "\n",
    "# Fitting the number of clusters to our bow representation of the text data\n",
    "clustersbow_2.fit(final_counts_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the cluster labels of the created model\n",
    "\n",
    "clustersbow_2.labels_\n",
    "\n",
    "# Assigning the cluster labels to our data\n",
    "\n",
    "text_reviews['Clustersbow2'] = clustersbow_2.labels_"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the top 10 reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Clustersbow2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This product serves me well as a source of ele...</td>\n",
       "      <td>b'product serv well sourc electrolyt long run ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This cat food was recommended by my vet becaus...</td>\n",
       "      <td>b'cat food recommend vet year old cleo cat tro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you're looking for an energy boost without ...</td>\n",
       "      <td>b'your look energi boost without artifici swee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"These are delicious! The chocolate is excelle...</td>\n",
       "      <td>b'delici chocol excel espresso bean perfect ro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After looking at the pictures someone put on h...</td>\n",
       "      <td>b'look pictur someon put show crush box write ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>If it were possible to give this product zero ...</td>\n",
       "      <td>b'possibl give product zero star would done hu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>To be fair only one of my twins got gas from t...</td>\n",
       "      <td>b'fair one twin got gas horribl night scream g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This is my favorite hot sauce. I buy it locall...</td>\n",
       "      <td>b'favorit hot sauc buy local love flavor hope ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>My cats love this food. For the money it is a ...</td>\n",
       "      <td>b'cat love food money great product get everi ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>For christmas I ordered some coupons from my d...</td>\n",
       "      <td>b'christma order coupon daughter school ohama ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                             Reviews  \\\n",
       "0  This product serves me well as a source of ele...   \n",
       "1  This cat food was recommended by my vet becaus...   \n",
       "2  If you're looking for an energy boost without ...   \n",
       "3  \"These are delicious! The chocolate is excelle...   \n",
       "4  After looking at the pictures someone put on h...   \n",
       "5  If it were possible to give this product zero ...   \n",
       "6  To be fair only one of my twins got gas from t...   \n",
       "7  This is my favorite hot sauce. I buy it locall...   \n",
       "8  My cats love this food. For the money it is a ...   \n",
       "9  For christmas I ordered some coupons from my d...   \n",
       "\n",
       "                                        Cleaned_Text  Clustersbow2  \n",
       "0  b'product serv well sourc electrolyt long run ...             0  \n",
       "1  b'cat food recommend vet year old cleo cat tro...             0  \n",
       "2  b'your look energi boost without artifici swee...             0  \n",
       "3  b'delici chocol excel espresso bean perfect ro...             0  \n",
       "4  b'look pictur someon put show crush box write ...             0  \n",
       "5  b'possibl give product zero star would done hu...             0  \n",
       "6  b'fair one twin got gas horribl night scream g...             0  \n",
       "7  b'favorit hot sauc buy local love flavor hope ...             0  \n",
       "8  b'cat love food money great product get everi ...             0  \n",
       "9  b'christma order coupon daughter school ohama ...             0  "
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We will take a look at the first few rows of the data frame\n",
    "\n",
    "text_reviews.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1], dtype=int64)"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us check the unique values of the clustersbow2 column\n",
    "\n",
    "text_reviews['Clustersbow2'].unique()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Clustersbow2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This product serves me well as a source of ele...</td>\n",
       "      <td>b'product serv well sourc electrolyt long run ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This cat food was recommended by my vet becaus...</td>\n",
       "      <td>b'cat food recommend vet year old cleo cat tro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you're looking for an energy boost without ...</td>\n",
       "      <td>b'your look energi boost without artifici swee...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"These are delicious! The chocolate is excelle...</td>\n",
       "      <td>b'delici chocol excel espresso bean perfect ro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After looking at the pictures someone put on h...</td>\n",
       "      <td>b'look pictur someon put show crush box write ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>If it were possible to give this product zero ...</td>\n",
       "      <td>b'possibl give product zero star would done hu...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>To be fair only one of my twins got gas from t...</td>\n",
       "      <td>b'fair one twin got gas horribl night scream g...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This is my favorite hot sauce. I buy it locall...</td>\n",
       "      <td>b'favorit hot sauc buy local love flavor hope ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>My cats love this food. For the money it is a ...</td>\n",
       "      <td>b'cat love food money great product get everi ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>For christmas I ordered some coupons from my d...</td>\n",
       "      <td>b'christma order coupon daughter school ohama ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I was looking for a healthier alternative to S...</td>\n",
       "      <td>b'look healthier altern splenda equal nustevia...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I subscribe to several Hormel Compleats. This ...</td>\n",
       "      <td>b'subscrib sever hormel compleat definit best ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The flavors are kind of funky salt and pepper?...</td>\n",
       "      <td>b'flavor kind funki salt pepper tast like some...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I love these.  I love any floral flavored prod...</td>\n",
       "      <td>b'love love floral flavor product best part pe...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I love this pancake mix.  I bought my first ca...</td>\n",
       "      <td>b'love pancak mix bought first whole food mark...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>We first had Stonewall Waffle Mix when we rece...</td>\n",
       "      <td>b'first stonewal waffl mix receiv gift basket ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I give Merrick canned food as a treat and mix ...</td>\n",
       "      <td>b'give merrick can food treat mix dog dri kibb...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>better then I expected. I notice there was som...</td>\n",
       "      <td>b'better expect notic complaint muffin dri spr...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Was shocked at the skinny size of this item!! ...</td>\n",
       "      <td>b'shock skinni size item five inch long expect...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I ordered the Mahogany Caribou Coffee K-Cups a...</td>\n",
       "      <td>b'order mahogani caribou coffe ador recommend ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>When I received the package just earlier today...</td>\n",
       "      <td>b'receiv packag earlier today excit tri immedi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>This popcorn has alot of hulls I order 4 bags ...</td>\n",
       "      <td>b'popcorn alot hull order bag cant stand eat h...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>absolutely delicious  have tried it on everyth...</td>\n",
       "      <td>b'absolut delici tri everyth meat fish scrambl...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>This is good popcorn, I have purchased before ...</td>\n",
       "      <td>b'good popcorn purchas hawaii happi see order ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>great deal, especially for the price. Item arr...</td>\n",
       "      <td>b'great deal especi price item arriv quicker a...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>i have tried many brands of the hot chocolates...</td>\n",
       "      <td>b'tri mani brand hot chocol far best realiz th...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>As a hot chocolate lover, I was verrrrry disap...</td>\n",
       "      <td>b'hot chocol lover verrrrri disappoint tri pro...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I love these noodles.  They are really great f...</td>\n",
       "      <td>b'love noodl realli great midnight snack reall...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>very good corn product, we will be eating this...</td>\n",
       "      <td>b'good corn product eat case corn way faster e...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>This is a keeper flavor -- hope Tic Tac remove...</td>\n",
       "      <td>b'keeper flavor hope tic tac remov pink grapef...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>Tried it for the first time and really liked i...</td>\n",
       "      <td>b'tri first time realli like add extra rice do...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>In my opinion, this chicken biryani is the bes...</td>\n",
       "      <td>b'opinion chicken biryani best microwav chicke...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>We all love this oatmeal.  We usually use the ...</td>\n",
       "      <td>b'love oatmeal usual use overnight method time...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3960</th>\n",
       "      <td>The children love this. It takes over 30 minut...</td>\n",
       "      <td>b'children love take minut cook make extra put...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3961</th>\n",
       "      <td>This is the BEST oatmeal anywhere on the plane...</td>\n",
       "      <td>b'best oatmeal anywher planet found quick easi...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3962</th>\n",
       "      <td>I LOVE Click!  My favorite protein drink by fa...</td>\n",
       "      <td>b'love click favorit protein drink far add lit...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3963</th>\n",
       "      <td>Had my first one today - the vanilla latte!  I...</td>\n",
       "      <td>b'first one today vanilla latt great especi ic...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3964</th>\n",
       "      <td>The product arrived a day early and in excelle...</td>\n",
       "      <td>b'product arriv day earli excel condit love ri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3965</th>\n",
       "      <td>I am so surprised that they have this popcorn ...</td>\n",
       "      <td>b'surpris popcorn sale receiv bag day special ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966</th>\n",
       "      <td>I bought a couple sets of these pens for my so...</td>\n",
       "      <td>b'bought coupl set pen son birthday parti kid ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3967</th>\n",
       "      <td>SBC's French Roast is fantastic!  Yes, I'm a S...</td>\n",
       "      <td>b'sbcs french roast fantast yes seattl coffe s...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3968</th>\n",
       "      <td>I hesitated to try this as, frankly, powdered ...</td>\n",
       "      <td>b'hesit tri frank powder peanut butter sound r...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3969</th>\n",
       "      <td>Tried this for the first time and couldn't bel...</td>\n",
       "      <td>b'tri first time couldnt believ easi turn grea...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>Recently I cannot get enough of these...I eat ...</td>\n",
       "      <td>b'recent cannot get enough eat watch anytim ge...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>I was worried about buying this because a lot ...</td>\n",
       "      <td>b'worri buy lot peopl havent review love came ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>Such an unsuspecting bottle, who would have th...</td>\n",
       "      <td>b'unsuspect bottl would thought never mind war...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>This is some awesome stuff but be warn extreme...</td>\n",
       "      <td>b'awesom stuff warn extrem hot love sooo much ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>Dear Sirs:&lt;br /&gt;&lt;br /&gt;  My Root Beer product w...</td>\n",
       "      <td>b'dear root beer product perfect howev contain...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>This French Roast coffee is a favorite for us....</td>\n",
       "      <td>b'french roast coffe favorit wife altern cafe ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>The illy pre ground works great for when I tra...</td>\n",
       "      <td>b'illi pre ground work great travel cant take ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>all reviews which compared illy cofee to lavaz...</td>\n",
       "      <td>b'review compar illi cofe lavazza much favor i...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>My mom was in a tough situation. I sent these ...</td>\n",
       "      <td>b'mom tough situat sent flower month ago every...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>When thinking about popcorn, the three things ...</td>\n",
       "      <td>b'think popcorn three thing think orvill reden...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>Delicious chocolate with a great fruity taste....</td>\n",
       "      <td>b'delici chocol great fruiti tast tri resist f...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>I order this product over and over again. It's...</td>\n",
       "      <td>b'order product healthi touch sweet lemon trul...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3982</th>\n",
       "      <td>Laura Scudder's Organic Smooth Peanut Butter, ...</td>\n",
       "      <td>b'laura scudder organ smooth peanut butter buy...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>My cats haven't been this excited to eat since...</td>\n",
       "      <td>b'cat havent excit eat sinc time fed day fresh...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>I'd never heard of this brand but they were ve...</td>\n",
       "      <td>b'never heard brand cheap amazon extrem surpri...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3985</th>\n",
       "      <td>Everyone has their own preferences, I know -- ...</td>\n",
       "      <td>b'everyon prefer know actual like flavor wife ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>The salt liocorice was very good.  It came nic...</td>\n",
       "      <td>b'salt liocoric good came nice moist even thre...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3986 rows  3 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Reviews  \\\n",
       "0     This product serves me well as a source of ele...   \n",
       "1     This cat food was recommended by my vet becaus...   \n",
       "2     If you're looking for an energy boost without ...   \n",
       "3     \"These are delicious! The chocolate is excelle...   \n",
       "4     After looking at the pictures someone put on h...   \n",
       "5     If it were possible to give this product zero ...   \n",
       "6     To be fair only one of my twins got gas from t...   \n",
       "7     This is my favorite hot sauce. I buy it locall...   \n",
       "8     My cats love this food. For the money it is a ...   \n",
       "9     For christmas I ordered some coupons from my d...   \n",
       "10    I was looking for a healthier alternative to S...   \n",
       "11    I subscribe to several Hormel Compleats. This ...   \n",
       "12    The flavors are kind of funky salt and pepper?...   \n",
       "13    I love these.  I love any floral flavored prod...   \n",
       "14    I love this pancake mix.  I bought my first ca...   \n",
       "15    We first had Stonewall Waffle Mix when we rece...   \n",
       "16    I give Merrick canned food as a treat and mix ...   \n",
       "17    better then I expected. I notice there was som...   \n",
       "18    Was shocked at the skinny size of this item!! ...   \n",
       "19    I ordered the Mahogany Caribou Coffee K-Cups a...   \n",
       "20    When I received the package just earlier today...   \n",
       "21    This popcorn has alot of hulls I order 4 bags ...   \n",
       "22    absolutely delicious  have tried it on everyth...   \n",
       "23    This is good popcorn, I have purchased before ...   \n",
       "24    great deal, especially for the price. Item arr...   \n",
       "25    i have tried many brands of the hot chocolates...   \n",
       "26    As a hot chocolate lover, I was verrrrry disap...   \n",
       "27    I love these noodles.  They are really great f...   \n",
       "28    very good corn product, we will be eating this...   \n",
       "29    This is a keeper flavor -- hope Tic Tac remove...   \n",
       "...                                                 ...   \n",
       "3957  Tried it for the first time and really liked i...   \n",
       "3958  In my opinion, this chicken biryani is the bes...   \n",
       "3959  We all love this oatmeal.  We usually use the ...   \n",
       "3960  The children love this. It takes over 30 minut...   \n",
       "3961  This is the BEST oatmeal anywhere on the plane...   \n",
       "3962  I LOVE Click!  My favorite protein drink by fa...   \n",
       "3963  Had my first one today - the vanilla latte!  I...   \n",
       "3964  The product arrived a day early and in excelle...   \n",
       "3965  I am so surprised that they have this popcorn ...   \n",
       "3966  I bought a couple sets of these pens for my so...   \n",
       "3967  SBC's French Roast is fantastic!  Yes, I'm a S...   \n",
       "3968  I hesitated to try this as, frankly, powdered ...   \n",
       "3969  Tried this for the first time and couldn't bel...   \n",
       "3970  Recently I cannot get enough of these...I eat ...   \n",
       "3971  I was worried about buying this because a lot ...   \n",
       "3972  Such an unsuspecting bottle, who would have th...   \n",
       "3973  This is some awesome stuff but be warn extreme...   \n",
       "3974  Dear Sirs:<br /><br />  My Root Beer product w...   \n",
       "3975  This French Roast coffee is a favorite for us....   \n",
       "3976  The illy pre ground works great for when I tra...   \n",
       "3977  all reviews which compared illy cofee to lavaz...   \n",
       "3978  My mom was in a tough situation. I sent these ...   \n",
       "3979  When thinking about popcorn, the three things ...   \n",
       "3980  Delicious chocolate with a great fruity taste....   \n",
       "3981  I order this product over and over again. It's...   \n",
       "3982  Laura Scudder's Organic Smooth Peanut Butter, ...   \n",
       "3983  My cats haven't been this excited to eat since...   \n",
       "3984  I'd never heard of this brand but they were ve...   \n",
       "3985  Everyone has their own preferences, I know -- ...   \n",
       "3986  The salt liocorice was very good.  It came nic...   \n",
       "\n",
       "                                           Cleaned_Text  Clustersbow2  \n",
       "0     b'product serv well sourc electrolyt long run ...             0  \n",
       "1     b'cat food recommend vet year old cleo cat tro...             0  \n",
       "2     b'your look energi boost without artifici swee...             0  \n",
       "3     b'delici chocol excel espresso bean perfect ro...             0  \n",
       "4     b'look pictur someon put show crush box write ...             0  \n",
       "5     b'possibl give product zero star would done hu...             0  \n",
       "6     b'fair one twin got gas horribl night scream g...             0  \n",
       "7     b'favorit hot sauc buy local love flavor hope ...             0  \n",
       "8     b'cat love food money great product get everi ...             0  \n",
       "9     b'christma order coupon daughter school ohama ...             0  \n",
       "10    b'look healthier altern splenda equal nustevia...             0  \n",
       "11    b'subscrib sever hormel compleat definit best ...             0  \n",
       "12    b'flavor kind funki salt pepper tast like some...             0  \n",
       "13    b'love love floral flavor product best part pe...             0  \n",
       "14    b'love pancak mix bought first whole food mark...             0  \n",
       "15    b'first stonewal waffl mix receiv gift basket ...             0  \n",
       "16    b'give merrick can food treat mix dog dri kibb...             0  \n",
       "17    b'better expect notic complaint muffin dri spr...             0  \n",
       "18    b'shock skinni size item five inch long expect...             0  \n",
       "19    b'order mahogani caribou coffe ador recommend ...             0  \n",
       "20    b'receiv packag earlier today excit tri immedi...             0  \n",
       "21    b'popcorn alot hull order bag cant stand eat h...             0  \n",
       "22    b'absolut delici tri everyth meat fish scrambl...             0  \n",
       "23    b'good popcorn purchas hawaii happi see order ...             0  \n",
       "24    b'great deal especi price item arriv quicker a...             0  \n",
       "25    b'tri mani brand hot chocol far best realiz th...             0  \n",
       "26    b'hot chocol lover verrrrri disappoint tri pro...             0  \n",
       "27    b'love noodl realli great midnight snack reall...             0  \n",
       "28    b'good corn product eat case corn way faster e...             0  \n",
       "29    b'keeper flavor hope tic tac remov pink grapef...             0  \n",
       "...                                                 ...           ...  \n",
       "3957  b'tri first time realli like add extra rice do...             0  \n",
       "3958  b'opinion chicken biryani best microwav chicke...             0  \n",
       "3959  b'love oatmeal usual use overnight method time...             0  \n",
       "3960  b'children love take minut cook make extra put...             0  \n",
       "3961  b'best oatmeal anywher planet found quick easi...             0  \n",
       "3962  b'love click favorit protein drink far add lit...             0  \n",
       "3963  b'first one today vanilla latt great especi ic...             0  \n",
       "3964  b'product arriv day earli excel condit love ri...             0  \n",
       "3965  b'surpris popcorn sale receiv bag day special ...             0  \n",
       "3966  b'bought coupl set pen son birthday parti kid ...             0  \n",
       "3967  b'sbcs french roast fantast yes seattl coffe s...             0  \n",
       "3968  b'hesit tri frank powder peanut butter sound r...             0  \n",
       "3969  b'tri first time couldnt believ easi turn grea...             0  \n",
       "3970  b'recent cannot get enough eat watch anytim ge...             0  \n",
       "3971  b'worri buy lot peopl havent review love came ...             0  \n",
       "3972  b'unsuspect bottl would thought never mind war...             0  \n",
       "3973  b'awesom stuff warn extrem hot love sooo much ...             0  \n",
       "3974  b'dear root beer product perfect howev contain...             0  \n",
       "3975  b'french roast coffe favorit wife altern cafe ...             0  \n",
       "3976  b'illi pre ground work great travel cant take ...             0  \n",
       "3977  b'review compar illi cofe lavazza much favor i...             0  \n",
       "3978  b'mom tough situat sent flower month ago every...             0  \n",
       "3979  b'think popcorn three thing think orvill reden...             0  \n",
       "3980  b'delici chocol great fruiti tast tri resist f...             0  \n",
       "3981  b'order product healthi touch sweet lemon trul...             0  \n",
       "3982  b'laura scudder organ smooth peanut butter buy...             0  \n",
       "3983  b'cat havent excit eat sinc time fed day fresh...             0  \n",
       "3984  b'never heard brand cheap amazon extrem surpri...             0  \n",
       "3985  b'everyon prefer know actual like flavor wife ...             0  \n",
       "3986  b'salt liocoric good came nice moist even thre...             0  \n",
       "\n",
       "[3986 rows x 3 columns]"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading a few rows of the cluster label 0\n",
    "\n",
    "text_reviews.loc[text_reviews['Clustersbow2'] == 0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conslusion from cluster 0"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can see lot of words being used such as 'great', 'good', 'refreshing','energizing', 'love','delicious' etc. Thus, we can say that the label 0 may be representing all the positive reviews."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Reading the reviews with cluster label 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Clustersbow2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>938</th>\n",
       "      <td>Diamond Almonds&lt;br /&gt;Almonds are a good source...</td>\n",
       "      <td>b'diamond almond almond good sourc magnesium o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                               Reviews  \\\n",
       "938  Diamond Almonds<br />Almonds are a good source...   \n",
       "\n",
       "                                          Cleaned_Text  Clustersbow2  \n",
       "938  b'diamond almond almond good sourc magnesium o...             1  "
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_reviews.loc[text_reviews['Clustersbow2'] == 1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Conclusion from cluster label 1"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "We can see that from cluster label 1 the number of words such as 'good', 'great','love' etc are very less as compared to class 0. Thus we can infer that cluster labelled 1 does not contain positive reviews."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3986\n",
       "1       1\n",
       "Name: Clustersbow2, dtype: int64"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us look at how many unique values have been assigned to each cluster\n",
    "\n",
    "text_reviews['Clustersbow2'].value_counts()\n",
    "\n",
    "# We can see that the number of clusters into which the data has been divided is quite unbalanced, we can try increasing the number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating a TF-IDF representation of the reviews data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_idf_vect = TfidfVectorizer()\n",
    "final_tf_idf = tf_idf_vect.fit_transform(final_text['Cleaned_Text'].values).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.matrixlib.defmatrix.matrix'>\n"
     ]
    }
   ],
   "source": [
    "# Checking the data-type of final_tf_idf\n",
    "\n",
    "print(type(final_tf_idf))\n",
    "\n",
    "# it is a matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Converting the matrix to an array\n",
    "\n",
    "final_tfidf_array = np.squeeze(np.asarray(final_tf_idf))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "# Checking the datatype of the array\n",
    "\n",
    "print(type(final_tfidf_array))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying K-Medoids to TF-IDF representation of reviews data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considering 2 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "# First we will consider only 2 clusters\n",
    "# Creating 2 as the number of clusters \n",
    "clusterstfidf_2 = KMedoids(n_clusters=2)\n",
    "\n",
    "# Fitting the number of clusters to our bow representation of the text data\n",
    "clusterstfidf_2.fit(final_tfidf_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Extracting the cluster labels of the created model\n",
    "\n",
    "clusterstfidf_2.labels_\n",
    "\n",
    "# Assigning the cluster labels to our data\n",
    "\n",
    "text_reviews['Clusterstfidf2'] = clusterstfidf_2.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Clustersbow2</th>\n",
       "      <th>Clusterstfidf2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>This product serves me well as a source of ele...</td>\n",
       "      <td>b'product serv well sourc electrolyt long run ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>This cat food was recommended by my vet becaus...</td>\n",
       "      <td>b'cat food recommend vet year old cleo cat tro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>If you're looking for an energy boost without ...</td>\n",
       "      <td>b'your look energi boost without artifici swee...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>\"These are delicious! The chocolate is excelle...</td>\n",
       "      <td>b'delici chocol excel espresso bean perfect ro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>After looking at the pictures someone put on h...</td>\n",
       "      <td>b'look pictur someon put show crush box write ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>If it were possible to give this product zero ...</td>\n",
       "      <td>b'possibl give product zero star would done hu...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>To be fair only one of my twins got gas from t...</td>\n",
       "      <td>b'fair one twin got gas horribl night scream g...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>This is my favorite hot sauce. I buy it locall...</td>\n",
       "      <td>b'favorit hot sauc buy local love flavor hope ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>My cats love this food. For the money it is a ...</td>\n",
       "      <td>b'cat love food money great product get everi ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>For christmas I ordered some coupons from my d...</td>\n",
       "      <td>b'christma order coupon daughter school ohama ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10</th>\n",
       "      <td>I was looking for a healthier alternative to S...</td>\n",
       "      <td>b'look healthier altern splenda equal nustevia...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>I subscribe to several Hormel Compleats. This ...</td>\n",
       "      <td>b'subscrib sever hormel compleat definit best ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>12</th>\n",
       "      <td>The flavors are kind of funky salt and pepper?...</td>\n",
       "      <td>b'flavor kind funki salt pepper tast like some...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>13</th>\n",
       "      <td>I love these.  I love any floral flavored prod...</td>\n",
       "      <td>b'love love floral flavor product best part pe...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>14</th>\n",
       "      <td>I love this pancake mix.  I bought my first ca...</td>\n",
       "      <td>b'love pancak mix bought first whole food mark...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>15</th>\n",
       "      <td>We first had Stonewall Waffle Mix when we rece...</td>\n",
       "      <td>b'first stonewal waffl mix receiv gift basket ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>16</th>\n",
       "      <td>I give Merrick canned food as a treat and mix ...</td>\n",
       "      <td>b'give merrick can food treat mix dog dri kibb...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>17</th>\n",
       "      <td>better then I expected. I notice there was som...</td>\n",
       "      <td>b'better expect notic complaint muffin dri spr...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>18</th>\n",
       "      <td>Was shocked at the skinny size of this item!! ...</td>\n",
       "      <td>b'shock skinni size item five inch long expect...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>19</th>\n",
       "      <td>I ordered the Mahogany Caribou Coffee K-Cups a...</td>\n",
       "      <td>b'order mahogani caribou coffe ador recommend ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>20</th>\n",
       "      <td>When I received the package just earlier today...</td>\n",
       "      <td>b'receiv packag earlier today excit tri immedi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>21</th>\n",
       "      <td>This popcorn has alot of hulls I order 4 bags ...</td>\n",
       "      <td>b'popcorn alot hull order bag cant stand eat h...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>22</th>\n",
       "      <td>absolutely delicious  have tried it on everyth...</td>\n",
       "      <td>b'absolut delici tri everyth meat fish scrambl...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>This is good popcorn, I have purchased before ...</td>\n",
       "      <td>b'good popcorn purchas hawaii happi see order ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>24</th>\n",
       "      <td>great deal, especially for the price. Item arr...</td>\n",
       "      <td>b'great deal especi price item arriv quicker a...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25</th>\n",
       "      <td>i have tried many brands of the hot chocolates...</td>\n",
       "      <td>b'tri mani brand hot chocol far best realiz th...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>26</th>\n",
       "      <td>As a hot chocolate lover, I was verrrrry disap...</td>\n",
       "      <td>b'hot chocol lover verrrrri disappoint tri pro...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>I love these noodles.  They are really great f...</td>\n",
       "      <td>b'love noodl realli great midnight snack reall...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28</th>\n",
       "      <td>very good corn product, we will be eating this...</td>\n",
       "      <td>b'good corn product eat case corn way faster e...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>29</th>\n",
       "      <td>This is a keeper flavor -- hope Tic Tac remove...</td>\n",
       "      <td>b'keeper flavor hope tic tac remov pink grapef...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3957</th>\n",
       "      <td>Tried it for the first time and really liked i...</td>\n",
       "      <td>b'tri first time realli like add extra rice do...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3958</th>\n",
       "      <td>In my opinion, this chicken biryani is the bes...</td>\n",
       "      <td>b'opinion chicken biryani best microwav chicke...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3959</th>\n",
       "      <td>We all love this oatmeal.  We usually use the ...</td>\n",
       "      <td>b'love oatmeal usual use overnight method time...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3960</th>\n",
       "      <td>The children love this. It takes over 30 minut...</td>\n",
       "      <td>b'children love take minut cook make extra put...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3961</th>\n",
       "      <td>This is the BEST oatmeal anywhere on the plane...</td>\n",
       "      <td>b'best oatmeal anywher planet found quick easi...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3962</th>\n",
       "      <td>I LOVE Click!  My favorite protein drink by fa...</td>\n",
       "      <td>b'love click favorit protein drink far add lit...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3963</th>\n",
       "      <td>Had my first one today - the vanilla latte!  I...</td>\n",
       "      <td>b'first one today vanilla latt great especi ic...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3964</th>\n",
       "      <td>The product arrived a day early and in excelle...</td>\n",
       "      <td>b'product arriv day earli excel condit love ri...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3965</th>\n",
       "      <td>I am so surprised that they have this popcorn ...</td>\n",
       "      <td>b'surpris popcorn sale receiv bag day special ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3966</th>\n",
       "      <td>I bought a couple sets of these pens for my so...</td>\n",
       "      <td>b'bought coupl set pen son birthday parti kid ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3967</th>\n",
       "      <td>SBC's French Roast is fantastic!  Yes, I'm a S...</td>\n",
       "      <td>b'sbcs french roast fantast yes seattl coffe s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3968</th>\n",
       "      <td>I hesitated to try this as, frankly, powdered ...</td>\n",
       "      <td>b'hesit tri frank powder peanut butter sound r...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3969</th>\n",
       "      <td>Tried this for the first time and couldn't bel...</td>\n",
       "      <td>b'tri first time couldnt believ easi turn grea...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3970</th>\n",
       "      <td>Recently I cannot get enough of these...I eat ...</td>\n",
       "      <td>b'recent cannot get enough eat watch anytim ge...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3971</th>\n",
       "      <td>I was worried about buying this because a lot ...</td>\n",
       "      <td>b'worri buy lot peopl havent review love came ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3972</th>\n",
       "      <td>Such an unsuspecting bottle, who would have th...</td>\n",
       "      <td>b'unsuspect bottl would thought never mind war...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3973</th>\n",
       "      <td>This is some awesome stuff but be warn extreme...</td>\n",
       "      <td>b'awesom stuff warn extrem hot love sooo much ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3974</th>\n",
       "      <td>Dear Sirs:&lt;br /&gt;&lt;br /&gt;  My Root Beer product w...</td>\n",
       "      <td>b'dear root beer product perfect howev contain...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3975</th>\n",
       "      <td>This French Roast coffee is a favorite for us....</td>\n",
       "      <td>b'french roast coffe favorit wife altern cafe ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3976</th>\n",
       "      <td>The illy pre ground works great for when I tra...</td>\n",
       "      <td>b'illi pre ground work great travel cant take ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3977</th>\n",
       "      <td>all reviews which compared illy cofee to lavaz...</td>\n",
       "      <td>b'review compar illi cofe lavazza much favor i...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3978</th>\n",
       "      <td>My mom was in a tough situation. I sent these ...</td>\n",
       "      <td>b'mom tough situat sent flower month ago every...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3979</th>\n",
       "      <td>When thinking about popcorn, the three things ...</td>\n",
       "      <td>b'think popcorn three thing think orvill reden...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3980</th>\n",
       "      <td>Delicious chocolate with a great fruity taste....</td>\n",
       "      <td>b'delici chocol great fruiti tast tri resist f...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3981</th>\n",
       "      <td>I order this product over and over again. It's...</td>\n",
       "      <td>b'order product healthi touch sweet lemon trul...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3982</th>\n",
       "      <td>Laura Scudder's Organic Smooth Peanut Butter, ...</td>\n",
       "      <td>b'laura scudder organ smooth peanut butter buy...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3983</th>\n",
       "      <td>My cats haven't been this excited to eat since...</td>\n",
       "      <td>b'cat havent excit eat sinc time fed day fresh...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3984</th>\n",
       "      <td>I'd never heard of this brand but they were ve...</td>\n",
       "      <td>b'never heard brand cheap amazon extrem surpri...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3985</th>\n",
       "      <td>Everyone has their own preferences, I know -- ...</td>\n",
       "      <td>b'everyon prefer know actual like flavor wife ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3986</th>\n",
       "      <td>The salt liocorice was very good.  It came nic...</td>\n",
       "      <td>b'salt liocoric good came nice moist even thre...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>3937 rows  4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Reviews  \\\n",
       "0     This product serves me well as a source of ele...   \n",
       "1     This cat food was recommended by my vet becaus...   \n",
       "2     If you're looking for an energy boost without ...   \n",
       "3     \"These are delicious! The chocolate is excelle...   \n",
       "4     After looking at the pictures someone put on h...   \n",
       "5     If it were possible to give this product zero ...   \n",
       "6     To be fair only one of my twins got gas from t...   \n",
       "7     This is my favorite hot sauce. I buy it locall...   \n",
       "8     My cats love this food. For the money it is a ...   \n",
       "9     For christmas I ordered some coupons from my d...   \n",
       "10    I was looking for a healthier alternative to S...   \n",
       "11    I subscribe to several Hormel Compleats. This ...   \n",
       "12    The flavors are kind of funky salt and pepper?...   \n",
       "13    I love these.  I love any floral flavored prod...   \n",
       "14    I love this pancake mix.  I bought my first ca...   \n",
       "15    We first had Stonewall Waffle Mix when we rece...   \n",
       "16    I give Merrick canned food as a treat and mix ...   \n",
       "17    better then I expected. I notice there was som...   \n",
       "18    Was shocked at the skinny size of this item!! ...   \n",
       "19    I ordered the Mahogany Caribou Coffee K-Cups a...   \n",
       "20    When I received the package just earlier today...   \n",
       "21    This popcorn has alot of hulls I order 4 bags ...   \n",
       "22    absolutely delicious  have tried it on everyth...   \n",
       "23    This is good popcorn, I have purchased before ...   \n",
       "24    great deal, especially for the price. Item arr...   \n",
       "25    i have tried many brands of the hot chocolates...   \n",
       "26    As a hot chocolate lover, I was verrrrry disap...   \n",
       "27    I love these noodles.  They are really great f...   \n",
       "28    very good corn product, we will be eating this...   \n",
       "29    This is a keeper flavor -- hope Tic Tac remove...   \n",
       "...                                                 ...   \n",
       "3957  Tried it for the first time and really liked i...   \n",
       "3958  In my opinion, this chicken biryani is the bes...   \n",
       "3959  We all love this oatmeal.  We usually use the ...   \n",
       "3960  The children love this. It takes over 30 minut...   \n",
       "3961  This is the BEST oatmeal anywhere on the plane...   \n",
       "3962  I LOVE Click!  My favorite protein drink by fa...   \n",
       "3963  Had my first one today - the vanilla latte!  I...   \n",
       "3964  The product arrived a day early and in excelle...   \n",
       "3965  I am so surprised that they have this popcorn ...   \n",
       "3966  I bought a couple sets of these pens for my so...   \n",
       "3967  SBC's French Roast is fantastic!  Yes, I'm a S...   \n",
       "3968  I hesitated to try this as, frankly, powdered ...   \n",
       "3969  Tried this for the first time and couldn't bel...   \n",
       "3970  Recently I cannot get enough of these...I eat ...   \n",
       "3971  I was worried about buying this because a lot ...   \n",
       "3972  Such an unsuspecting bottle, who would have th...   \n",
       "3973  This is some awesome stuff but be warn extreme...   \n",
       "3974  Dear Sirs:<br /><br />  My Root Beer product w...   \n",
       "3975  This French Roast coffee is a favorite for us....   \n",
       "3976  The illy pre ground works great for when I tra...   \n",
       "3977  all reviews which compared illy cofee to lavaz...   \n",
       "3978  My mom was in a tough situation. I sent these ...   \n",
       "3979  When thinking about popcorn, the three things ...   \n",
       "3980  Delicious chocolate with a great fruity taste....   \n",
       "3981  I order this product over and over again. It's...   \n",
       "3982  Laura Scudder's Organic Smooth Peanut Butter, ...   \n",
       "3983  My cats haven't been this excited to eat since...   \n",
       "3984  I'd never heard of this brand but they were ve...   \n",
       "3985  Everyone has their own preferences, I know -- ...   \n",
       "3986  The salt liocorice was very good.  It came nic...   \n",
       "\n",
       "                                           Cleaned_Text  Clustersbow2  \\\n",
       "0     b'product serv well sourc electrolyt long run ...             0   \n",
       "1     b'cat food recommend vet year old cleo cat tro...             0   \n",
       "2     b'your look energi boost without artifici swee...             0   \n",
       "3     b'delici chocol excel espresso bean perfect ro...             0   \n",
       "4     b'look pictur someon put show crush box write ...             0   \n",
       "5     b'possibl give product zero star would done hu...             0   \n",
       "6     b'fair one twin got gas horribl night scream g...             0   \n",
       "7     b'favorit hot sauc buy local love flavor hope ...             0   \n",
       "8     b'cat love food money great product get everi ...             0   \n",
       "9     b'christma order coupon daughter school ohama ...             0   \n",
       "10    b'look healthier altern splenda equal nustevia...             0   \n",
       "11    b'subscrib sever hormel compleat definit best ...             0   \n",
       "12    b'flavor kind funki salt pepper tast like some...             0   \n",
       "13    b'love love floral flavor product best part pe...             0   \n",
       "14    b'love pancak mix bought first whole food mark...             0   \n",
       "15    b'first stonewal waffl mix receiv gift basket ...             0   \n",
       "16    b'give merrick can food treat mix dog dri kibb...             0   \n",
       "17    b'better expect notic complaint muffin dri spr...             0   \n",
       "18    b'shock skinni size item five inch long expect...             0   \n",
       "19    b'order mahogani caribou coffe ador recommend ...             0   \n",
       "20    b'receiv packag earlier today excit tri immedi...             0   \n",
       "21    b'popcorn alot hull order bag cant stand eat h...             0   \n",
       "22    b'absolut delici tri everyth meat fish scrambl...             0   \n",
       "23    b'good popcorn purchas hawaii happi see order ...             0   \n",
       "24    b'great deal especi price item arriv quicker a...             0   \n",
       "25    b'tri mani brand hot chocol far best realiz th...             0   \n",
       "26    b'hot chocol lover verrrrri disappoint tri pro...             0   \n",
       "27    b'love noodl realli great midnight snack reall...             0   \n",
       "28    b'good corn product eat case corn way faster e...             0   \n",
       "29    b'keeper flavor hope tic tac remov pink grapef...             0   \n",
       "...                                                 ...           ...   \n",
       "3957  b'tri first time realli like add extra rice do...             0   \n",
       "3958  b'opinion chicken biryani best microwav chicke...             0   \n",
       "3959  b'love oatmeal usual use overnight method time...             0   \n",
       "3960  b'children love take minut cook make extra put...             0   \n",
       "3961  b'best oatmeal anywher planet found quick easi...             0   \n",
       "3962  b'love click favorit protein drink far add lit...             0   \n",
       "3963  b'first one today vanilla latt great especi ic...             0   \n",
       "3964  b'product arriv day earli excel condit love ri...             0   \n",
       "3965  b'surpris popcorn sale receiv bag day special ...             0   \n",
       "3966  b'bought coupl set pen son birthday parti kid ...             0   \n",
       "3967  b'sbcs french roast fantast yes seattl coffe s...             0   \n",
       "3968  b'hesit tri frank powder peanut butter sound r...             0   \n",
       "3969  b'tri first time couldnt believ easi turn grea...             0   \n",
       "3970  b'recent cannot get enough eat watch anytim ge...             0   \n",
       "3971  b'worri buy lot peopl havent review love came ...             0   \n",
       "3972  b'unsuspect bottl would thought never mind war...             0   \n",
       "3973  b'awesom stuff warn extrem hot love sooo much ...             0   \n",
       "3974  b'dear root beer product perfect howev contain...             0   \n",
       "3975  b'french roast coffe favorit wife altern cafe ...             0   \n",
       "3976  b'illi pre ground work great travel cant take ...             0   \n",
       "3977  b'review compar illi cofe lavazza much favor i...             0   \n",
       "3978  b'mom tough situat sent flower month ago every...             0   \n",
       "3979  b'think popcorn three thing think orvill reden...             0   \n",
       "3980  b'delici chocol great fruiti tast tri resist f...             0   \n",
       "3981  b'order product healthi touch sweet lemon trul...             0   \n",
       "3982  b'laura scudder organ smooth peanut butter buy...             0   \n",
       "3983  b'cat havent excit eat sinc time fed day fresh...             0   \n",
       "3984  b'never heard brand cheap amazon extrem surpri...             0   \n",
       "3985  b'everyon prefer know actual like flavor wife ...             0   \n",
       "3986  b'salt liocoric good came nice moist even thre...             0   \n",
       "\n",
       "      Clusterstfidf2  \n",
       "0                  0  \n",
       "1                  0  \n",
       "2                  0  \n",
       "3                  0  \n",
       "4                  0  \n",
       "5                  0  \n",
       "6                  0  \n",
       "7                  0  \n",
       "8                  0  \n",
       "9                  0  \n",
       "10                 0  \n",
       "11                 0  \n",
       "12                 0  \n",
       "13                 0  \n",
       "14                 0  \n",
       "15                 0  \n",
       "16                 0  \n",
       "17                 0  \n",
       "18                 0  \n",
       "19                 0  \n",
       "20                 0  \n",
       "21                 0  \n",
       "22                 0  \n",
       "23                 0  \n",
       "24                 0  \n",
       "25                 0  \n",
       "26                 0  \n",
       "27                 0  \n",
       "28                 0  \n",
       "29                 0  \n",
       "...              ...  \n",
       "3957               0  \n",
       "3958               0  \n",
       "3959               0  \n",
       "3960               0  \n",
       "3961               0  \n",
       "3962               0  \n",
       "3963               0  \n",
       "3964               0  \n",
       "3965               0  \n",
       "3966               0  \n",
       "3967               0  \n",
       "3968               0  \n",
       "3969               0  \n",
       "3970               0  \n",
       "3971               0  \n",
       "3972               0  \n",
       "3973               0  \n",
       "3974               0  \n",
       "3975               0  \n",
       "3976               0  \n",
       "3977               0  \n",
       "3978               0  \n",
       "3979               0  \n",
       "3980               0  \n",
       "3981               0  \n",
       "3982               0  \n",
       "3983               0  \n",
       "3984               0  \n",
       "3985               0  \n",
       "3986               0  \n",
       "\n",
       "[3937 rows x 4 columns]"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading a few rows of the cluster label 0\n",
    "\n",
    "text_reviews.loc[text_reviews['Clusterstfidf2'] == 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Reviews</th>\n",
       "      <th>Cleaned_Text</th>\n",
       "      <th>Clustersbow2</th>\n",
       "      <th>Clusterstfidf2</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>33</th>\n",
       "      <td>A dark coffee that has no bitterness and is sm...</td>\n",
       "      <td>b'dark coffe bitter smooth silk alway use qual...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>111</th>\n",
       "      <td>We just recently joined the Keurig Craze.  We'...</td>\n",
       "      <td>b'recent join keurig craze weve tri ton differ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>276</th>\n",
       "      <td>I didn't get to each much of the bar I receive...</td>\n",
       "      <td>b'didnt get much bar receiv husband purloin sa...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>338</th>\n",
       "      <td>I like Cerelac product, they tast good and hav...</td>\n",
       "      <td>b'like cerelac product tast good lot varieti d...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>377</th>\n",
       "      <td>It's cheap, it tastes fine (not really flavour...</td>\n",
       "      <td>b'cheap tast fine realli flavour bad help lose...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>403</th>\n",
       "      <td>I have been looking all over, Amazon included,...</td>\n",
       "      <td>b'look amazon includ nice tea passion fruit ta...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>420</th>\n",
       "      <td>This is the best orange spice tea I have ever ...</td>\n",
       "      <td>b'best orang spice tea ever lot flavor'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>468</th>\n",
       "      <td>Compared to other bagged teas, this is delicio...</td>\n",
       "      <td>b'compar bag tea delici high aromat blend chai...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>476</th>\n",
       "      <td>Lipton To Go Iced Tea crystals are a convenien...</td>\n",
       "      <td>b'lipton ice tea crystal conveni way enjoy ice...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>549</th>\n",
       "      <td>Nigella in Arabic are the Seed of Blessing.  T...</td>\n",
       "      <td>b'nigella arab seed bless flavor deep savori l...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>663</th>\n",
       "      <td>I tried this tea in a Teavana store where samp...</td>\n",
       "      <td>b'tri tea teavana store sampl avail blossom be...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>685</th>\n",
       "      <td>We love bold coffees and this is the second bo...</td>\n",
       "      <td>b'love bold coffe second box doubl black diamo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>749</th>\n",
       "      <td>This K-cup saved my K-cup maker from extinctio...</td>\n",
       "      <td>b'save maker extinct use dark strong brew coff...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>750</th>\n",
       "      <td>If you want a very bold cup, this is it. It re...</td>\n",
       "      <td>b'want bold cup realli wake get go day howev f...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>798</th>\n",
       "      <td>I can appreciate the gentle, subtle mildness o...</td>\n",
       "      <td>b'appreci gentl subtl mild peko suppos prefer ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>883</th>\n",
       "      <td>The ingredients list is good, the product seem...</td>\n",
       "      <td>b'ingredi list good product seem made qualiti ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>906</th>\n",
       "      <td>I discovered that this particular flavor wakes...</td>\n",
       "      <td>b'discov particular flavor wake right long dri...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>962</th>\n",
       "      <td>I did not like any of the brew over iced tea f...</td>\n",
       "      <td>b'like brew ice tea flavor tri love would defi...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>974</th>\n",
       "      <td>Love this rich and flavorful brew.  I prefer i...</td>\n",
       "      <td>b'love rich flavor brew prefer starbuck best w...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>980</th>\n",
       "      <td>I found these first at my local supermarket.  ...</td>\n",
       "      <td>b'found first local supermarket ive look blend...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1128</th>\n",
       "      <td>Roasted red potatoes has become a staple of ou...</td>\n",
       "      <td>b'roast red potato becom stapl sunday brunch l...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1314</th>\n",
       "      <td>Scottish Breakfast Tea is a very robust tea.  ...</td>\n",
       "      <td>b'scottish breakfast tea robust tea although p...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1427</th>\n",
       "      <td>I really love these bags and use them with a L...</td>\n",
       "      <td>b'realli love bag use lil pal dispens found am...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1456</th>\n",
       "      <td>Bought these for my 16 pound Schnauzer and the...</td>\n",
       "      <td>b'bought pound schnauzer general right size lo...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1521</th>\n",
       "      <td>This mint with the tiny dot of licorice in the...</td>\n",
       "      <td>b'mint tini dot licoric center best mint ever ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1766</th>\n",
       "      <td>That's what my cat would say. This is the best...</td>\n",
       "      <td>b'that cat would say best food ive found cat e...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1883</th>\n",
       "      <td>These single-serve pods are everything good; E...</td>\n",
       "      <td>b'pod everyth ethic farm artesian rost organ y...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1998</th>\n",
       "      <td>I like the taste of black tea and since I am p...</td>\n",
       "      <td>b'like tast black tea sinc pregnant didnt want...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2052</th>\n",
       "      <td>This is a mild sea salt that does not have the...</td>\n",
       "      <td>b'mild sea salt harsh bite sea salt tabl salt ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2325</th>\n",
       "      <td>The stash black tea has a nice flavor, definit...</td>\n",
       "      <td>b'stash black tea nice flavor definit better l...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2347</th>\n",
       "      <td>I bought these to make chocolate dipped cookie...</td>\n",
       "      <td>b'bought make chocol dip cooki chines new year...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2416</th>\n",
       "      <td>I carefully read all the reviews on this Item ...</td>\n",
       "      <td>b'care read review item order must say mani re...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2591</th>\n",
       "      <td>I didn't like these.&lt;br /&gt;I guess it's my faul...</td>\n",
       "      <td>b'didnt like guess fault like actual never tri...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2631</th>\n",
       "      <td>\"There is a garden overlooking the Yangtze Riv...</td>\n",
       "      <td>b'garden overlook yangtz river gorg elder man ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2642</th>\n",
       "      <td>What we received tasted moldy - maybe the blos...</td>\n",
       "      <td>b'receiv tast moldi mayb blossom collect groun...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2674</th>\n",
       "      <td>This Keurig cup is very tasty.  It isn't quite...</td>\n",
       "      <td>b'keurig cup tasti isnt quit strong would like...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2741</th>\n",
       "      <td>This is the best orange spice tea I have ever ...</td>\n",
       "      <td>b'best orang spice tea ever lot flavor'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2747</th>\n",
       "      <td>This not only tastes great but has the best ar...</td>\n",
       "      <td>b'tast great best aroma brew subscrib save way'</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2782</th>\n",
       "      <td>It's a smooth blend - none of the extreme (to ...</td>\n",
       "      <td>b'smooth blend none extrem anyway bitter mani ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2963</th>\n",
       "      <td>This coffee is like none I have ever had. For ...</td>\n",
       "      <td>b'coffe like none ever starter come bag like t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3093</th>\n",
       "      <td>This tastes nothing like a slim jim to me so f...</td>\n",
       "      <td>b'tast noth like slim jim claim either havent ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3265</th>\n",
       "      <td>This is nowhere near as good as fresh brewed T...</td>\n",
       "      <td>b'nowher near good fresh brew thai tea cane su...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3327</th>\n",
       "      <td>This is an excellent tea with a full and heart...</td>\n",
       "      <td>b'excel tea full hearti qualiti enjoy mani var...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3459</th>\n",
       "      <td>I love Lipton's instant fruit teas.  I love br...</td>\n",
       "      <td>b'love lipton instant fruit tea love brew tea ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3515</th>\n",
       "      <td>I wanted to like this, but I didn't. It was to...</td>\n",
       "      <td>b'want like didnt sweet fact didnt tast much l...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3604</th>\n",
       "      <td>This is a pretty good puerh tea.  I think the ...</td>\n",
       "      <td>b'pretti good puerh tea think price bit high t...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3658</th>\n",
       "      <td>Taste is what it's all about and this tea not ...</td>\n",
       "      <td>b'tast tea tast good welcom chang morn coffe g...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3848</th>\n",
       "      <td>I buy extra bold coffee and brew it on the mug...</td>\n",
       "      <td>b'buy extra bold coffe brew mug size cuisinart...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3857</th>\n",
       "      <td>This is a great tea. I brew the bulk stuff in ...</td>\n",
       "      <td>b'great tea brew bulk stuff coffe maker quick ...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3911</th>\n",
       "      <td>I bought this tea because I was looking for a ...</td>\n",
       "      <td>b'bought tea look strong flavor plain black te...</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Reviews  \\\n",
       "33    A dark coffee that has no bitterness and is sm...   \n",
       "111   We just recently joined the Keurig Craze.  We'...   \n",
       "276   I didn't get to each much of the bar I receive...   \n",
       "338   I like Cerelac product, they tast good and hav...   \n",
       "377   It's cheap, it tastes fine (not really flavour...   \n",
       "403   I have been looking all over, Amazon included,...   \n",
       "420   This is the best orange spice tea I have ever ...   \n",
       "468   Compared to other bagged teas, this is delicio...   \n",
       "476   Lipton To Go Iced Tea crystals are a convenien...   \n",
       "549   Nigella in Arabic are the Seed of Blessing.  T...   \n",
       "663   I tried this tea in a Teavana store where samp...   \n",
       "685   We love bold coffees and this is the second bo...   \n",
       "749   This K-cup saved my K-cup maker from extinctio...   \n",
       "750   If you want a very bold cup, this is it. It re...   \n",
       "798   I can appreciate the gentle, subtle mildness o...   \n",
       "883   The ingredients list is good, the product seem...   \n",
       "906   I discovered that this particular flavor wakes...   \n",
       "962   I did not like any of the brew over iced tea f...   \n",
       "974   Love this rich and flavorful brew.  I prefer i...   \n",
       "980   I found these first at my local supermarket.  ...   \n",
       "1128  Roasted red potatoes has become a staple of ou...   \n",
       "1314  Scottish Breakfast Tea is a very robust tea.  ...   \n",
       "1427  I really love these bags and use them with a L...   \n",
       "1456  Bought these for my 16 pound Schnauzer and the...   \n",
       "1521  This mint with the tiny dot of licorice in the...   \n",
       "1766  That's what my cat would say. This is the best...   \n",
       "1883  These single-serve pods are everything good; E...   \n",
       "1998  I like the taste of black tea and since I am p...   \n",
       "2052  This is a mild sea salt that does not have the...   \n",
       "2325  The stash black tea has a nice flavor, definit...   \n",
       "2347  I bought these to make chocolate dipped cookie...   \n",
       "2416  I carefully read all the reviews on this Item ...   \n",
       "2591  I didn't like these.<br />I guess it's my faul...   \n",
       "2631  \"There is a garden overlooking the Yangtze Riv...   \n",
       "2642  What we received tasted moldy - maybe the blos...   \n",
       "2674  This Keurig cup is very tasty.  It isn't quite...   \n",
       "2741  This is the best orange spice tea I have ever ...   \n",
       "2747  This not only tastes great but has the best ar...   \n",
       "2782  It's a smooth blend - none of the extreme (to ...   \n",
       "2963  This coffee is like none I have ever had. For ...   \n",
       "3093  This tastes nothing like a slim jim to me so f...   \n",
       "3265  This is nowhere near as good as fresh brewed T...   \n",
       "3327  This is an excellent tea with a full and heart...   \n",
       "3459  I love Lipton's instant fruit teas.  I love br...   \n",
       "3515  I wanted to like this, but I didn't. It was to...   \n",
       "3604  This is a pretty good puerh tea.  I think the ...   \n",
       "3658  Taste is what it's all about and this tea not ...   \n",
       "3848  I buy extra bold coffee and brew it on the mug...   \n",
       "3857  This is a great tea. I brew the bulk stuff in ...   \n",
       "3911  I bought this tea because I was looking for a ...   \n",
       "\n",
       "                                           Cleaned_Text  Clustersbow2  \\\n",
       "33    b'dark coffe bitter smooth silk alway use qual...             0   \n",
       "111   b'recent join keurig craze weve tri ton differ...             0   \n",
       "276   b'didnt get much bar receiv husband purloin sa...             0   \n",
       "338   b'like cerelac product tast good lot varieti d...             0   \n",
       "377   b'cheap tast fine realli flavour bad help lose...             0   \n",
       "403   b'look amazon includ nice tea passion fruit ta...             0   \n",
       "420             b'best orang spice tea ever lot flavor'             0   \n",
       "468   b'compar bag tea delici high aromat blend chai...             0   \n",
       "476   b'lipton ice tea crystal conveni way enjoy ice...             0   \n",
       "549   b'nigella arab seed bless flavor deep savori l...             0   \n",
       "663   b'tri tea teavana store sampl avail blossom be...             0   \n",
       "685   b'love bold coffe second box doubl black diamo...             0   \n",
       "749   b'save maker extinct use dark strong brew coff...             0   \n",
       "750   b'want bold cup realli wake get go day howev f...             0   \n",
       "798   b'appreci gentl subtl mild peko suppos prefer ...             0   \n",
       "883   b'ingredi list good product seem made qualiti ...             0   \n",
       "906   b'discov particular flavor wake right long dri...             0   \n",
       "962   b'like brew ice tea flavor tri love would defi...             0   \n",
       "974   b'love rich flavor brew prefer starbuck best w...             0   \n",
       "980   b'found first local supermarket ive look blend...             0   \n",
       "1128  b'roast red potato becom stapl sunday brunch l...             0   \n",
       "1314  b'scottish breakfast tea robust tea although p...             0   \n",
       "1427  b'realli love bag use lil pal dispens found am...             0   \n",
       "1456  b'bought pound schnauzer general right size lo...             0   \n",
       "1521  b'mint tini dot licoric center best mint ever ...             0   \n",
       "1766  b'that cat would say best food ive found cat e...             0   \n",
       "1883  b'pod everyth ethic farm artesian rost organ y...             0   \n",
       "1998  b'like tast black tea sinc pregnant didnt want...             0   \n",
       "2052  b'mild sea salt harsh bite sea salt tabl salt ...             0   \n",
       "2325  b'stash black tea nice flavor definit better l...             0   \n",
       "2347  b'bought make chocol dip cooki chines new year...             0   \n",
       "2416  b'care read review item order must say mani re...             0   \n",
       "2591  b'didnt like guess fault like actual never tri...             0   \n",
       "2631  b'garden overlook yangtz river gorg elder man ...             0   \n",
       "2642  b'receiv tast moldi mayb blossom collect groun...             0   \n",
       "2674  b'keurig cup tasti isnt quit strong would like...             0   \n",
       "2741            b'best orang spice tea ever lot flavor'             0   \n",
       "2747    b'tast great best aroma brew subscrib save way'             0   \n",
       "2782  b'smooth blend none extrem anyway bitter mani ...             0   \n",
       "2963  b'coffe like none ever starter come bag like t...             0   \n",
       "3093  b'tast noth like slim jim claim either havent ...             0   \n",
       "3265  b'nowher near good fresh brew thai tea cane su...             0   \n",
       "3327  b'excel tea full hearti qualiti enjoy mani var...             0   \n",
       "3459  b'love lipton instant fruit tea love brew tea ...             0   \n",
       "3515  b'want like didnt sweet fact didnt tast much l...             0   \n",
       "3604  b'pretti good puerh tea think price bit high t...             0   \n",
       "3658  b'tast tea tast good welcom chang morn coffe g...             0   \n",
       "3848  b'buy extra bold coffe brew mug size cuisinart...             0   \n",
       "3857  b'great tea brew bulk stuff coffe maker quick ...             0   \n",
       "3911  b'bought tea look strong flavor plain black te...             0   \n",
       "\n",
       "      Clusterstfidf2  \n",
       "33                 1  \n",
       "111                1  \n",
       "276                1  \n",
       "338                1  \n",
       "377                1  \n",
       "403                1  \n",
       "420                1  \n",
       "468                1  \n",
       "476                1  \n",
       "549                1  \n",
       "663                1  \n",
       "685                1  \n",
       "749                1  \n",
       "750                1  \n",
       "798                1  \n",
       "883                1  \n",
       "906                1  \n",
       "962                1  \n",
       "974                1  \n",
       "980                1  \n",
       "1128               1  \n",
       "1314               1  \n",
       "1427               1  \n",
       "1456               1  \n",
       "1521               1  \n",
       "1766               1  \n",
       "1883               1  \n",
       "1998               1  \n",
       "2052               1  \n",
       "2325               1  \n",
       "2347               1  \n",
       "2416               1  \n",
       "2591               1  \n",
       "2631               1  \n",
       "2642               1  \n",
       "2674               1  \n",
       "2741               1  \n",
       "2747               1  \n",
       "2782               1  \n",
       "2963               1  \n",
       "3093               1  \n",
       "3265               1  \n",
       "3327               1  \n",
       "3459               1  \n",
       "3515               1  \n",
       "3604               1  \n",
       "3658               1  \n",
       "3848               1  \n",
       "3857               1  \n",
       "3911               1  "
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Reading a few rows of the cluster label 1\n",
    "\n",
    "text_reviews.loc[text_reviews['Clusterstfidf2'] == 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    3937\n",
       "1      50\n",
       "Name: Clusterstfidf2, dtype: int64"
      ]
     },
     "execution_count": 72,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Let us look at how many unique values have been assigned to each cluster\n",
    "\n",
    "text_reviews['Clusterstfidf2'].value_counts()\n",
    "\n",
    "# We can see that the number of clusters into which the data has been divided is quite unbalanced, we can try increasing the number of clusters"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating AvgW2Vec representation of the reviews data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kulkarni\\Anaconda3\\lib\\site-packages\\gensim\\utils.py:1197: UserWarning: detected Windows; aliasing chunkize to chunkize_serial\n",
      "  warnings.warn(\"detected Windows; aliasing chunkize to chunkize_serial\")\n"
     ]
    }
   ],
   "source": [
    "# Importing the required models for the project\n",
    "\n",
    "from gensim.models import Word2Vec\n",
    "from gensim.models import KeyedVectors\n",
    "import pickle"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "X2 = text_data.iloc[:,:].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "n = 568454\n",
    "m = 4000\n",
    "p = m/n\n",
    "\n",
    "text_data_sample = [];\n",
    "\n",
    "for i in range(0,n):\n",
    "    if random.random() <= p:\n",
    "        text_data_sample.append(X2[i,:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sample = pd.DataFrame(text_data_sample)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I don't know if it's the cactus or the tequila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I order these olives a lot. They are un-like a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is the first time I've really been misled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>They are good but need more cheese and wish th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eat at your own risk.  Once I would open a bag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0\n",
       "0  I don't know if it's the cactus or the tequila...\n",
       "1  I order these olives a lot. They are un-like a...\n",
       "2  This is the first time I've really been misled...\n",
       "3  They are good but need more cheese and wish th...\n",
       "4  Eat at your own risk.  Once I would open a bag..."
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sample.columns = ['Text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I don't know if it's the cactus or the tequila...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>I order these olives a lot. They are un-like a...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>This is the first time I've really been misled...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>They are good but need more cheese and wish th...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Eat at your own risk.  Once I would open a bag...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Text\n",
       "0  I don't know if it's the cactus or the tequila...\n",
       "1  I order these olives a lot. They are un-like a...\n",
       "2  This is the first time I've really been misled...\n",
       "3  They are good but need more cheese and wish th...\n",
       "4  Eat at your own risk.  Once I would open a bag..."
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "text_sample.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "import gensim\n",
    "i=0\n",
    "list_of_sent=[]\n",
    "for sent in text_sample['Text'].values:\n",
    "    filtered_sentence=[]\n",
    "    sent=cleanhtml(sent)\n",
    "    for w in sent.split():\n",
    "        for cleaned_words in cleanpunc(w).split():\n",
    "            if(cleaned_words.isalpha()):    \n",
    "                filtered_sentence.append(cleaned_words.lower())\n",
    "            else:\n",
    "                continue \n",
    "    list_of_sent.append(filtered_sentence)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "w2v_model=gensim.models.Word2Vec(list_of_sent,min_count=5,size=50, workers=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "3986\n",
      "50\n"
     ]
    }
   ],
   "source": [
    "# average Word2Vec\n",
    "# compute average word2vec for each review.\n",
    "sent_vectors = []; # the avg-w2v for each sentence/review is stored in this list\n",
    "for sent in list_of_sent: # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    cnt_words =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            sent_vec += vec\n",
    "            cnt_words += 1\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= cnt_words\n",
    "    sent_vectors.append(sent_vec)\n",
    "print(len(sent_vectors))\n",
    "print(len(sent_vectors[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'list'>\n"
     ]
    }
   ],
   "source": [
    "print(type(sent_vectors))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [],
   "source": [
    "sen_vectors_array= np.asarray(sent_vectors)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying K-Medoids Clustering on the Avg W2Vec representation of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considering 2 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pyclust\n",
    "from pyclust import KMedoids\n",
    "\n",
    "# Creating 2 as the number of clusters \n",
    "clustersavgw2vec_2 = KMedoids(n_clusters=2)\n",
    "\n",
    "# Fitting the number of clusters to our bow representation of the text data\n",
    "clustersavgw2vec_2.fit(sen_vectors_array)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "text_sample['Clusters_AvgW2Vec'] = clustersavgw2vec_2.labels_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Creating Tfidf weighted W2Vec representation of the text reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\kulkarni\\Anaconda3\\lib\\site-packages\\ipykernel_launcher.py:20: RuntimeWarning: invalid value encountered in true_divide\n"
     ]
    }
   ],
   "source": [
    "# TF-IDF weighted Word2Vec\n",
    "tfidf_feat = tf_idf_vect.get_feature_names() # tfidf words/col-names\n",
    "# final_tf_idf is the sparse matrix with row= sentence, col=word and cell_val = tfidf\n",
    "\n",
    "tfidf_sent_vectors = []; # the tfidf-w2v for each sentence/review is stored in this list\n",
    "row=0;\n",
    "for sent in list_of_sent: # for each review/sentence\n",
    "    sent_vec = np.zeros(50) # as word vectors are of zero length\n",
    "    weight_sum =0; # num of words with a valid vector in the sentence/review\n",
    "    for word in sent: # for each word in a review/sentence\n",
    "        try:\n",
    "            vec = w2v_model.wv[word]\n",
    "            # obtain the tf_idfidf of a word in a sentence/review\n",
    "            tf_idf = final_tf_idf[row, tfidf_feat.index(word)]\n",
    "            #tfidf = final_tf_idf[row, tfidf_feat.index(word)]\n",
    "            sent_vec += (vec * tf_idf)\n",
    "            weight_sum += tf_idf\n",
    "        except:\n",
    "            pass\n",
    "    sent_vec /= weight_sum\n",
    "    tfidf_sent_vectors.append(sent_vec)\n",
    "    row += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 53,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking for any 'NaN' values in the data\n",
    "\n",
    "np.isnan(tfidf_sent_vectors).any()\n",
    "\n",
    "# We can see that there are na values in the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [],
   "source": [
    "# We will replace all the 'Nan' values w/ mean of the respective columns\n",
    "\n",
    "\n",
    "from sklearn.preprocessing import Imputer\n",
    "imp = Imputer(missing_values='NaN', strategy='mean', axis=0)\n",
    "data_tfidf = imp.fit_transform(tfidf_sent_vectors) # Assigning the imputed matrix w/o Nan values to data variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "numpy.ndarray"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking the type of 'data_tfidf' \n",
    "\n",
    "type(data_tfidf)\n",
    "\n",
    "# It is an array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "False"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Checking if our imputation has succeded\n",
    "\n",
    "np.isnan(data_tfidf).any()\n",
    "\n",
    "# We can see that there are no na values any more."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Applying K-Medoids Clustering on the Tf-Idf weighted W2Vec representation of the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Considering 2 clusters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "attempt to get argmin of an empty sequence",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-58-8c02b14dee44>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m()\u001b[0m\n\u001b[0;32m      6\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      7\u001b[0m \u001b[1;31m# Fitting the number of clusters to our bow representation of the text data\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m----> 8\u001b[1;33m \u001b[0mclusterstfidfw2vec_2\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdata_tfidf\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyclust\\_kmedoids.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X)\u001b[0m\n\u001b[0;32m    132\u001b[0m         \"\"\"\n\u001b[0;32m    133\u001b[0m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcenters_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mlabels_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msse_arr_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_iter_\u001b[0m \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 134\u001b[1;33m               \u001b[0m_kmedoids\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mrng\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    135\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    136\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyclust\\_kmedoids.py\u001b[0m in \u001b[0;36m_kmedoids\u001b[1;34m(X, n_clusters, distance, max_iter, n_trials, tol, rng)\u001b[0m\n\u001b[0;32m     60\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_trials\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     61\u001b[0m         \u001b[0mcenters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msse_tot\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msse_arr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_iter\u001b[0m  \u001b[1;33m=\u001b[0m\u001b[0;31m \u001b[0m\u001b[0;31m\\\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 62\u001b[1;33m                \u001b[0m_kmedoids_run\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmax_iter\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrng\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     63\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mi\u001b[0m\u001b[1;33m==\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     64\u001b[0m             \u001b[0msse_tot_best\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0msse_tot\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyclust\\_kmedoids.py\u001b[0m in \u001b[0;36m_kmedoids_run\u001b[1;34m(X, n_clusters, distance, max_iter, tol, rng)\u001b[0m\n\u001b[0;32m     40\u001b[0m     \u001b[1;32mfor\u001b[0m \u001b[0mit\u001b[0m \u001b[1;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0mmax_iter\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     41\u001b[0m         \u001b[0mmembs\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mkmeans\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_assign_clusters\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcenters\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 42\u001b[1;33m         \u001b[0mcenters\u001b[0m\u001b[1;33m,\u001b[0m\u001b[0msse_arr\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0m_update_centers\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmembs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_clusters\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     43\u001b[0m         \u001b[0msse_total\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msse_arr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     44\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mabs\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msse_total\u001b[0m \u001b[1;33m-\u001b[0m \u001b[0msse_last\u001b[0m\u001b[1;33m)\u001b[0m \u001b[1;33m<\u001b[0m \u001b[0mtol\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\pyclust\\_kmedoids.py\u001b[0m in \u001b[0;36m_update_centers\u001b[1;34m(X, membs, n_clusters, distance)\u001b[0m\n\u001b[0;32m     22\u001b[0m            \u001b[0mdist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mi\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0msum\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mscipy\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mspatial\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdistance\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mcdist\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_clust\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0marray\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mx\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mdistance\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     23\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 24\u001b[1;33m         \u001b[0minx_min\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mnp\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margmin\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mdist\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     25\u001b[0m         \u001b[0mcenters\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclust_id\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX_clust\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minx_min\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     26\u001b[0m         \u001b[0msse\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0mclust_id\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mdist\u001b[0m\u001b[1;33m[\u001b[0m\u001b[0minx_min\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36margmin\u001b[1;34m(a, axis, out)\u001b[0m\n\u001b[0;32m   1066\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1067\u001b[0m     \"\"\"\n\u001b[1;32m-> 1068\u001b[1;33m     \u001b[1;32mreturn\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0ma\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;34m'argmin'\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0maxis\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0maxis\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mout\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mout\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1069\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1070\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m~\\Anaconda3\\lib\\site-packages\\numpy\\core\\fromnumeric.py\u001b[0m in \u001b[0;36m_wrapfunc\u001b[1;34m(obj, method, *args, **kwds)\u001b[0m\n\u001b[0;32m     50\u001b[0m \u001b[1;32mdef\u001b[0m \u001b[0m_wrapfunc\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     51\u001b[0m     \u001b[1;32mtry\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 52\u001b[1;33m         \u001b[1;32mreturn\u001b[0m \u001b[0mgetattr\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mmethod\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     53\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     54\u001b[0m     \u001b[1;31m# An AttributeError occurs if the object does not have\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mValueError\u001b[0m: attempt to get argmin of an empty sequence"
     ]
    }
   ],
   "source": [
    "import pyclust\n",
    "from pyclust import KMedoids\n",
    "\n",
    "# Creating 2 as the number of clusters \n",
    "clusterstfidfw2vec_2 = KMedoids(n_clusters=2)\n",
    "\n",
    "# Fitting the number of clusters to our bow representation of the text data\n",
    "clusterstfidfw2vec_2.fit(data_tfidf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
